{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic Modeling using LDA",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Let's get the dataset."
      ],
      "metadata": {
        "id": "KWOH4yBTpVeY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ajewPOQBltjo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/vaccination2.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are going to use CountVectorizer to create the\n",
        "bag-of-words matrix as input to the LDA, and use scikit-learn’s built-in English stop word library via stop_words=’english"
      ],
      "metadata": {
        "id": "KhNPFTZVpdhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count = CountVectorizer(stop_words='english',\n",
        "max_df=.1,\n",
        "max_features=5000)\n",
        "X = count.fit_transform(df['tweet'].values.astype('U'))"
      ],
      "metadata": {
        "id": "T8fWhNZvlv-m"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set the maximum document frequency of words to be considered\n",
        "to 10 percent ( max_df=.1 ) to exclude words that occur too frequently across\n",
        "documents.We limited the number of words to be considered to the most frequently occurring 5,000 words(max_features=5000 ),to limit the dimensionality of this dataset so that it improves the inference performed by LDA."
      ],
      "metadata": {
        "id": "hcKaD5MtprSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda = LatentDirichletAllocation(n_components\n",
        "\n",
        "=10,\n",
        "random_state=123,learning_method='batch')\n",
        "X_topics = lda.fit_transform(X)"
      ],
      "metadata": {
        "id": "byOZlDXmlztm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After fitting the LDA, we now have access to the components_ attribute of the lda instance, which stores a matrix containing the word importance (here, 5000 ) for each of the 10 topics in increasing order:"
      ],
      "metadata": {
        "id": "x-0U4u4Ip3wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda.components_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W89SLz2ol2X9",
        "outputId": "c8dfc623-4169-47a2-bff5-3d0ebb29482d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets analyse the result"
      ],
      "metadata": {
        "id": "mYDvgjpxp-Gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_top_words = 5\n",
        "feature_names = count.get_feature_names()\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "  print(\"Topic %d:\" % (topic_idx + 1))\n",
        "  print(\" \".join([feature_names[i]\n",
        "  for i in topic.argsort()\\\n",
        "        [:-n_top_words - 1:-1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB7aC7gtl4ql",
        "outputId": "3592ab5e-6999-4ec5-f981-cccda3803f8a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1:\n",
            "rabies status free clinic dog\n",
            "Topic 2:\n",
            "just like don people know\n",
            "Topic 3:\n",
            "measles polio children disease diseases\n",
            "Topic 4:\n",
            "hpv cancer 2019 anti social\n",
            "Topic 5:\n",
            "anti vaccines autism people science\n",
            "Topic 6:\n",
            "ly health bit hepatitis fever\n",
            "Topic 7:\n",
            "news rates india livestock pm\n",
            "Topic 8:\n",
            "flu gov vaccines influenza cdc\n",
            "Topic 9:\n",
            "2019 california new health support\n",
            "Topic 10:\n",
            "school children parents kids mandatory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    }
  ]
}